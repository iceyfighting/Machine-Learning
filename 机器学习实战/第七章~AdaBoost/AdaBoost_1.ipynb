{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadSimpData():\n",
    "    \"\"\"\n",
    "    创建单层决策树的数据集\n",
    "    Parameters:\n",
    "        无\n",
    "    Returns:\n",
    "        dataMat - 数据矩阵\n",
    "        classLabels - 数据标签\n",
    "    \"\"\"\n",
    "    datMat = np.matrix([[ 1. ,  2.1],\n",
    "        [ 1.5,  1.6],\n",
    "        [ 1.3,  1. ],\n",
    "        [ 1. ,  1. ],\n",
    "        [ 2. ,  1. ]])\n",
    "    classLabels = [1.0, 1.0, -1.0, -1.0, 1.0]\n",
    "    return datMat,classLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def showDataSet(dataMat, labelMat):\n",
    "    \"\"\"\n",
    "    数据可视化\n",
    "    Parameters:\n",
    "        dataMat - 数据矩阵\n",
    "        labelMat - 数据标签\n",
    "    Returns:\n",
    "        无\n",
    "    \"\"\"\n",
    "    data_plus = []          #正样本\n",
    "    data_minus = []         #负样本\n",
    "    for i in range(len(dataMat)):\n",
    "        if labelMat[i] > 0:\n",
    "            data_plus.append(dataMat[i])\n",
    "        else:\n",
    "            data_minus.append(dataMat[i])\n",
    "    data_plus_np = np.array(data_plus)      #转换为numpy矩阵\n",
    "    data_minus_np = np.array(data_minus)    #转换为numpy矩阵\n",
    "    plt.scatter(np.transpose(data_plus_np)[0], np.transpose(data_plus_np)[1])  #正样本散点图\n",
    "    plt.scatter(np.transpose(data_minus_np)[0], np.transpose(data_minus_np)[1]) #负样本散点图\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7pLUIOMuSQ36PwjCCYOLiy5vAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x89b7588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    dataArr,classLabels = loadSimpData()\n",
    "    showDataSet(dataArr,classLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#测试是否有某个值小于或大于我们正在测试的阈值\n",
    "def stumpClassify(dataMatrix,dimen,threshVal,threshIneq):\n",
    "    \"\"\"\n",
    "    单层决策树分类函数\n",
    "    Parameters:\n",
    "        dataMatrix - 数据矩阵\n",
    "        dimen - 第dimen列，也就是第几个特征\n",
    "        threshVal - 阈值\n",
    "        threshIneq - 标志\n",
    "    Returns:\n",
    "        retArray - 分类结果\n",
    "    \"\"\"\n",
    "    retArray = np.ones((np.shape(dataMatrix)[0],1)) #初始化retArray为1\n",
    "    if threshIneq == 'lt':\n",
    "        retArray[dataMatrix[:,dimen] <= threshVal] = -1.0  #如果小于阈值,则赋值为-1\n",
    "    else:\n",
    "        retArray[dataMatrix[:,dimen] > threshVal] = -1.0   #如果大于阈值,则赋值为-1\n",
    "    return retArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "def buildStump(dataArr,classLabels,D):\n",
    "    \"\"\"\n",
    "    找到数据集上最佳的单层决策树\n",
    "    Parameters:\n",
    "        dataArr - 数据矩阵\n",
    "        classLabels - 数据标签\n",
    "        D - 样本权重\n",
    "    Returns:\n",
    "        bestStump - 最佳单层决策树信息\n",
    "        minError - 最小误差\n",
    "        bestClasEst - 最佳的分类结果\n",
    "    \"\"\"\n",
    "    dataMatrix = np.mat(dataArr); labelMat = np.mat(classLabels).T\n",
    "    m,n = np.shape(dataMatrix)\n",
    "    numSteps = 10.0; bestStump = {}; bestClasEst = np.mat(np.zeros((m,1)))\n",
    "    minError = float('inf') #最小误差初始化为正无穷大\n",
    "    for i in range(n):  #遍历所有特征\n",
    "        rangeMin = dataMatrix[:,i].min(); rangeMax = dataMatrix[:,i].max() #找到特征中最小的值和最大值\n",
    "        stepSize = (rangeMax - rangeMin) / numSteps #计算步长\n",
    "        for j in range(-1, int(numSteps) + 1): #对每个步长                                    \n",
    "            for inequal in ['lt', 'gt']:#大于和小于的情况，均遍历。lt:less than，gt:greater than\n",
    "                threshVal = (rangeMin + float(j) * stepSize) #计算阈值\n",
    "                predictedVals = stumpClassify(dataMatrix, i, threshVal, inequal)#计算分类结果\n",
    "                errArr = np.mat(np.ones((m,1))) #初始化误差矩阵为全一\n",
    "                errArr[predictedVals == labelMat] = 0   #分类正确的,赋值为0\n",
    "                weightedError = D.T * errArr     #计算误差\n",
    "                print(\"split: dim %d, thresh %.2f, thresh ineqal: %s, the weighted error is %.3f\" % (i, threshVal, inequal, weightedError))\n",
    "                if weightedError < minError:    #找到误差最小的分类方式\n",
    "                    minError = weightedError\n",
    "                    bestClasEst = predictedVals.copy()\n",
    "                    bestStump['dim'] = i\n",
    "                    bestStump['thresh'] = threshVal\n",
    "                    bestStump['ineq'] = inequal\n",
    "    return bestStump,minError,bestClasEst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split: dim 0, thresh 0.90, thresh ineqal: lt, the weighted error is 0.400\n",
      "split: dim 0, thresh 0.90, thresh ineqal: gt, the weighted error is 0.600\n",
      "split: dim 0, thresh 1.00, thresh ineqal: lt, the weighted error is 0.400\n",
      "split: dim 0, thresh 1.00, thresh ineqal: gt, the weighted error is 0.600\n",
      "split: dim 0, thresh 1.10, thresh ineqal: lt, the weighted error is 0.400\n",
      "split: dim 0, thresh 1.10, thresh ineqal: gt, the weighted error is 0.600\n",
      "split: dim 0, thresh 1.20, thresh ineqal: lt, the weighted error is 0.400\n",
      "split: dim 0, thresh 1.20, thresh ineqal: gt, the weighted error is 0.600\n",
      "split: dim 0, thresh 1.30, thresh ineqal: lt, the weighted error is 0.200\n",
      "split: dim 0, thresh 1.30, thresh ineqal: gt, the weighted error is 0.800\n",
      "split: dim 0, thresh 1.40, thresh ineqal: lt, the weighted error is 0.200\n",
      "split: dim 0, thresh 1.40, thresh ineqal: gt, the weighted error is 0.800\n",
      "split: dim 0, thresh 1.50, thresh ineqal: lt, the weighted error is 0.400\n",
      "split: dim 0, thresh 1.50, thresh ineqal: gt, the weighted error is 0.600\n",
      "split: dim 0, thresh 1.60, thresh ineqal: lt, the weighted error is 0.400\n",
      "split: dim 0, thresh 1.60, thresh ineqal: gt, the weighted error is 0.600\n",
      "split: dim 0, thresh 1.70, thresh ineqal: lt, the weighted error is 0.400\n",
      "split: dim 0, thresh 1.70, thresh ineqal: gt, the weighted error is 0.600\n",
      "split: dim 0, thresh 1.80, thresh ineqal: lt, the weighted error is 0.400\n",
      "split: dim 0, thresh 1.80, thresh ineqal: gt, the weighted error is 0.600\n",
      "split: dim 0, thresh 1.90, thresh ineqal: lt, the weighted error is 0.400\n",
      "split: dim 0, thresh 1.90, thresh ineqal: gt, the weighted error is 0.600\n",
      "split: dim 0, thresh 2.00, thresh ineqal: lt, the weighted error is 0.600\n",
      "split: dim 0, thresh 2.00, thresh ineqal: gt, the weighted error is 0.400\n",
      "split: dim 1, thresh 0.89, thresh ineqal: lt, the weighted error is 0.400\n",
      "split: dim 1, thresh 0.89, thresh ineqal: gt, the weighted error is 0.600\n",
      "split: dim 1, thresh 1.00, thresh ineqal: lt, the weighted error is 0.200\n",
      "split: dim 1, thresh 1.00, thresh ineqal: gt, the weighted error is 0.800\n",
      "split: dim 1, thresh 1.11, thresh ineqal: lt, the weighted error is 0.200\n",
      "split: dim 1, thresh 1.11, thresh ineqal: gt, the weighted error is 0.800\n",
      "split: dim 1, thresh 1.22, thresh ineqal: lt, the weighted error is 0.200\n",
      "split: dim 1, thresh 1.22, thresh ineqal: gt, the weighted error is 0.800\n",
      "split: dim 1, thresh 1.33, thresh ineqal: lt, the weighted error is 0.200\n",
      "split: dim 1, thresh 1.33, thresh ineqal: gt, the weighted error is 0.800\n",
      "split: dim 1, thresh 1.44, thresh ineqal: lt, the weighted error is 0.200\n",
      "split: dim 1, thresh 1.44, thresh ineqal: gt, the weighted error is 0.800\n",
      "split: dim 1, thresh 1.55, thresh ineqal: lt, the weighted error is 0.200\n",
      "split: dim 1, thresh 1.55, thresh ineqal: gt, the weighted error is 0.800\n",
      "split: dim 1, thresh 1.66, thresh ineqal: lt, the weighted error is 0.400\n",
      "split: dim 1, thresh 1.66, thresh ineqal: gt, the weighted error is 0.600\n",
      "split: dim 1, thresh 1.77, thresh ineqal: lt, the weighted error is 0.400\n",
      "split: dim 1, thresh 1.77, thresh ineqal: gt, the weighted error is 0.600\n",
      "split: dim 1, thresh 1.88, thresh ineqal: lt, the weighted error is 0.400\n",
      "split: dim 1, thresh 1.88, thresh ineqal: gt, the weighted error is 0.600\n",
      "split: dim 1, thresh 1.99, thresh ineqal: lt, the weighted error is 0.400\n",
      "split: dim 1, thresh 1.99, thresh ineqal: gt, the weighted error is 0.600\n",
      "split: dim 1, thresh 2.10, thresh ineqal: lt, the weighted error is 0.600\n",
      "split: dim 1, thresh 2.10, thresh ineqal: gt, the weighted error is 0.400\n",
      "bestStump:\n",
      " {'dim': 0, 'thresh': 1.3, 'ineq': 'lt'}\n",
      "minError:\n",
      " [[ 0.2]]\n",
      "bestClasEst:\n",
      " [[-1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [ 1.]]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    dataArr,classLabels = loadSimpData()\n",
    "    D = np.mat(np.ones((5, 1)) / 5)\n",
    "    bestStump,minError,bestClasEst = buildStump(dataArr,classLabels,D)\n",
    "    print('bestStump:\\n', bestStump)\n",
    "    print('minError:\\n', minError)\n",
    "    print('bestClasEst:\\n', bestClasEst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
