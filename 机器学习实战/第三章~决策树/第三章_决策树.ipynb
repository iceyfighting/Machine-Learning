{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 程序清单3-1 计算给定数据集的香农熵\n",
    "from math import log\n",
    "\n",
    "def calcShannonEnt(dataSet):\n",
    "    numEntries = len(dataSet)#计算行数，即数据集的总数\n",
    "    labelCounts = {}#定义一个字典\n",
    "    for featVec in dataSet:\n",
    "        currentLabel = featVec[-1]#最后一列是标签即结果是鱼或者不是鱼\n",
    "        #print(currentLabel)#\n",
    "        if currentLabel not in labelCounts.keys():#如果当前字典的值不在我们定义的字典中，则加入\n",
    "            labelCounts[currentLabel] = 0#标签字典值为0，即当前键值不存在\n",
    "        labelCounts[currentLabel] += 1#否则，标签字典值加1，加入字典中\n",
    "    #print(labelCounts.keys())\n",
    "    #print(labelCounts[currentLabel])\n",
    "    shannonEnt = 0.0\n",
    "    for key in labelCounts:#字典的值的遍历方式\n",
    "        prob = float(labelCounts[key]) / numEntries#某分类的概率\n",
    "        shannonEnt -= prob * log(prob, 2)#计算熵的公式\n",
    "    return shannonEnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createDataSet():\n",
    "    dataSet = [\n",
    "              [1, 1, 'yes'],\n",
    "              [1, 1, 'yes'],\n",
    "              [1, 0, 'no'],\n",
    "              [0, 1, 'no'],\n",
    "              [0, 1, 'no']]\n",
    "    labels = ['no surfacing', 'flippers']\n",
    "    return dataSet, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9709505944546686\n"
     ]
    }
   ],
   "source": [
    "myDat, labels = createDataSet()\n",
    "#print(myDat)\n",
    "print(calcShannonEnt(myDat))#计算信息熵\n",
    "\n",
    "#myDat[0][-1] = 'maybe'  # 熵越高，则混合的数据也越多\n",
    "#print(myDat)\n",
    "#print(calcShannonEnt(myDat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#程序清单 3-2 按照给定特征划分数据集\n",
    "def splitDataSet(dataSet, axis, value):\n",
    "    retDataSet = []\n",
    "    for featVec in dataSet:\n",
    "        if featVec[axis] == value:\n",
    "            reducedFeatVec = featVec[:axis] \n",
    "            #print(reducedFeatVec)\n",
    "            reducedFeatVec.extend(featVec[axis + 1 : ])#增加一个元素\n",
    "            #print(featVec[axis + 1 : ])\n",
    "            retDataSet.append(reducedFeatVec)#添加一个列表\n",
    "            #print(reducedFeatVec)\n",
    "    return retDataSet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]\n",
      "[[1, 'yes'], [1, 'yes'], [0, 'no'], [0, 'no']]\n"
     ]
    }
   ],
   "source": [
    "myDat, labels = createDataSet()\n",
    "print(myDat)\n",
    "\n",
    "#print(splitDataSet(myDat, 0, 1))#如果第一列为value，则输出一行中的值(除去value)\n",
    "#print(splitDataSet(myDat, 0, 0))\n",
    "print(splitDataSet(myDat, 1, 1))\n",
    "#print(splitDataSet(myDat, 1, 0))\n",
    "#print(myDat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 程序清单 3-3 选择最好的数据集划分方式\n",
    "def chooseBestFeatureToSplit(dataSet):\n",
    "    numFeatures = len(dataSet[0]) - 1#dataSet[0]第一行[1, 1, 'yes']\n",
    "#     print(dataSet[0])\n",
    "#     print(numFeatures)\n",
    "    baseEntropy = calcShannonEnt(dataSet)#计算香农熵\n",
    "    bestInfoGain = 0.0; bestFeature = -1\n",
    "    for i in np.arange(numFeatures):\n",
    "        featList = [example[i] for example in dataSet]#按列输出数据\n",
    "        print(featList)\n",
    "        uniqueVals = set(featList)#set集合{}去掉重复元素\n",
    "        newEntropy = 0.0\n",
    "        for value in uniqueVals:\n",
    "            subDataSet = splitDataSet(dataSet, i, value)\n",
    "            prob = len(subDataSet) / float(len(dataSet))\n",
    "            newEntropy += prob * calcShannonEnt(subDataSet) \n",
    "        infoGain = baseEntropy - newEntropy#信息增益\n",
    "        if infoGain > bestInfoGain:#找到信息增益最大的列并返回\n",
    "            bestInfoGain = infoGain\n",
    "            bestFeature = i\n",
    "    return bestFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 0, 0]\n",
      "[1, 1, 0, 1, 1]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "myDat, labels = createDataSet()\n",
    "print(chooseBestFeatureToSplit(myDat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 如果数据集已经处理了所有属性，但是类标签依然不是唯一的，此时我们需要决定如何定义该叶子节点，\n",
    "# 在这种情况下，我们通常会采用 多数表决的方法决定该叶子节点的分类\n",
    "def majorityCnt(classList):\n",
    "    classCount = {}#定义一个字典\n",
    "    for vote in classList:\n",
    "        if vote not in classCount.keys():#存储字典中的不同值并计算不同值的个数\n",
    "            classCount[vote] = 0\n",
    "        classCount[vote] += 1\n",
    "    \n",
    "    newvalue = -1\n",
    "    for key in classCount:#找出最大值\n",
    "        if newvalue < classCount[key]:\n",
    "            newkey = key\n",
    "            newvalue = classCount[key]\n",
    "    return newkey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 程序清单 3-4 创建树的函数代码\n",
    "def createTree(dataSet, labels): # 两个输入参数-- 数据集， 标签列表\n",
    "    classList = [example[-1] for example in dataSet]#把标签保存到classList中\n",
    "    if classList.count(classList[0]) == len(classList):\n",
    "        return classList[0]   # 如果类别完全相同则停止继续划分\n",
    "    \n",
    "    if len(dataSet[0]) == 1:  # 遍历完所有特征时返回出现次数最多的类别\n",
    "        return majorityCnt(classList) \n",
    "    \n",
    "    bestFeat = chooseBestFeatureToSplit(dataSet)#找出最好的用于划分的特征\n",
    "    bestFeatLabel = labels[bestFeat]#'no surfacing\n",
    "    myTree = {bestFeatLabel:{}}\n",
    "    del(labels[bestFeat])\n",
    "    \n",
    "    featValues = [example[bestFeat] for example in dataSet]\n",
    "    uniqueVals = set(featValues)\n",
    "    for value in uniqueVals:\n",
    "        subLabels = labels[:]  # 这行代码复制了类标签\n",
    "        myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet, bestFeat, value), subLabels) # 字典的嵌套\n",
    "        #print('1  ',bestFeatLabel,' ',value,' ',myTree[bestFeatLabel][value])\n",
    "    #print('2 ',myTree, '\\n')\n",
    "    return myTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 0, 0]\n",
      "[1, 1, 0, 1, 1]\n",
      "[1, 1, 0]\n",
      "{'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}\n"
     ]
    }
   ],
   "source": [
    "myDat, labels = createDataSet()\n",
    "myTree = createTree(myDat, labels)\n",
    "print(myTree)\n",
    "# {'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 程序清单3-8 使用决策树的分类函数\n",
    "def classify(inputTree, featLabels, testVec):\n",
    "    firstStr = list(inputTree.keys())[0]#字典中的键\n",
    "    #print(inputTree.keys())\n",
    "    #print(firstStr)\n",
    "    secondDict = inputTree[firstStr]#no surfacing对应的值\n",
    "    featIndex = featLabels.index(firstStr)#在featLabels中索引到no surfacing的位置\n",
    "    #print('1 ',featIndex)\n",
    "    for key in secondDict.keys():#\n",
    "        if testVec[featIndex] == key:#若我们测试的值和树的值一样，说明找到对的位置\n",
    "            if isinstance(secondDict[key], dict):#若该值是字典类型，继续找\n",
    "                classLabel = classify(secondDict[key], featLabels, testVec)\n",
    "            else:#不然就找到了\n",
    "                classLabel = secondDict[key]\n",
    "    return classLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['no surfacing', 'flippers']\n",
      "{'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}\n",
      "yes\n"
     ]
    }
   ],
   "source": [
    "myDat, labels = createDataSet()\n",
    "print(labels)\n",
    "#myTree = retrieveTree(0)\n",
    "print(myTree)\n",
    "#print(inputTree)\n",
    "#print(classify(myTree, labels, [1, 0]))\n",
    "print(classify(myTree, labels, [1, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 程序清单 3-9 使用pickle模块存储决策树\n",
    "import pickle\n",
    "def storeTree(inputTree, filename):\n",
    "    fw = open(filename, 'wb')\n",
    "    pickle.dump(inputTree, fw)#存储\n",
    "    fw.close()\n",
    "    \n",
    "def grabTree(filename):\n",
    "    fr = open(filename, 'rb')\n",
    "    return pickle.load(fr)#读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}\n"
     ]
    }
   ],
   "source": [
    "myDat, labels = createDataSet()\n",
    "#print(labels)\n",
    "myTree = createTree(myDat, labels)\n",
    "\n",
    "storeTree(myTree, r'E:\\Program Files\\Machine Learning\\机器学习实战及配套代码\\machinelearninginaction\\Ch03\\a.txt')#先存储\n",
    "\n",
    "print(grabTree(r'E:\\Program Files\\Machine Learning\\机器学习实战及配套代码\\machinelearninginaction\\Ch03\\a.txt'))#后读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tearRate': {'reduced': 'no lenses', 'normal': {'astigmatic': {'yes': {'prescript': {'hyper': {'age': {'pre': 'no lenses', 'young': 'hard', 'presbyopic': 'no lenses'}}, 'myope': 'hard'}}, 'no': {'age': {'pre': 'soft', 'young': 'soft', 'presbyopic': {'prescript': {'hyper': 'soft', 'myope': 'no lenses'}}}}}}}}\n"
     ]
    }
   ],
   "source": [
    "fr = open(r'E:\\Program Files\\Machine Learning\\机器学习实战及配套代码\\machinelearninginaction\\Ch03\\lenses.txt')\n",
    "lenses = [inst.strip().split('\\t') for inst in fr.readlines()]\n",
    "# print(lenses)\n",
    "lensesLabels = ['age', 'prescript', 'astigmatic', 'tearRate']\n",
    "lensesTree = createTree(lenses, lensesLabels)\n",
    "print(lensesTree)\n",
    "#createPlot(lensesTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 'yes', 3]\n",
      "[1, 1, 'yes', 3, [5, 6, 7]]\n"
     ]
    }
   ],
   "source": [
    "list = [1, 1, 'yes']\n",
    "list.extend([3])\n",
    "print(list)\n",
    "list.append([5,6,7])\n",
    "print(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
